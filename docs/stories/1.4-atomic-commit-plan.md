# Atomic Commit Plan: Story 1.4

**Total Commits:** 8
**Test Coverage:** 20/20 tests (9 P0, 9 P1, 2 P2)
**AC Coverage:** 8/8 acceptance criteria

---

## Commit 1: build(exceptions): add ValidationError exception class

**Tests:** 1.4-UNIT-002
**ACs:** 1
**Priority:** P0

**Setup:**
- Add `ValidationError` exception class to `src/momo/utils/exceptions.py`
  - Must be a subclass of `DataError`
  - Include docstring explaining usage for data quality validation failures
- Create test file `tests/stories/1.4/unit/test_1_4_unit_002.py`
  - Test that `ValidationError` imports correctly
  - Test that `ValidationError` is subclass of `DataError`
  - Test that raising `ValidationError` can be caught as `DataError`
  - Add `@pytest.mark.p0` and `@pytest.mark.unit` markers

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_002.py -v` (passes)
- Run: `uv run mypy src/momo/utils/exceptions.py` (passes)
- Verify `ValidationError` is importable and inherits from `DataError`

---

## Commit 2: feat(validation): implement ValidationReport dataclass and validate_prices skeleton

**Tests:** 1.4-UNIT-001, 1.4-UNIT-003, 1.4-UNIT-004
**ACs:** 1, 2, 6
**Priority:** P0

**Setup:**
- Create `tests/stories/1.4/conftest.py` with initial fixtures:
  - `sample_price_df_clean` - 5 tickers, 10 trading days, MultiIndex (date, symbol), all required columns
- Create test files with P0/unit markers:
  - `tests/stories/1.4/unit/test_1_4_unit_001.py` - Test ValidationReport has all required fields
  - `tests/stories/1.4/unit/test_1_4_unit_003.py` - Test validate_prices() accepts MultiIndex DataFrame
  - `tests/stories/1.4/unit/test_1_4_unit_004.py` - Test validate_prices() returns ValidationReport
- Create `src/momo/data/validation.py` module with:
  - Module docstring with usage example
  - `ValidationReport` dataclass with all required fields: `total_tickers`, `date_range`, `missing_data_counts`, `date_gaps`, `adjustment_issues`, `delisting_events`, `summary_message`, `is_valid`
  - `validate_prices()` function skeleton that:
    - Accepts DataFrame with MultiIndex (date, symbol)
    - Returns minimal ValidationReport (no validation logic yet, just structure)
    - Preserves input DataFrame (no mutation)
  - All functions have type hints and docstrings

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_00[1,3,4].py -v` (all pass)
- Run: `uv run mypy src/momo/data/validation.py` (passes)
- Verify ValidationReport dataclass structure is correct
- Verify validate_prices() accepts MultiIndex DataFrame without error

---

## Commit 3: feat(validation): implement missing data detection with NaN checks

**Tests:** 1.4-UNIT-005, 1.4-UNIT-006, 1.4-UNIT-007
**ACs:** 2
**Priority:** P0

**Setup:**
- Add fixtures to `tests/stories/1.4/conftest.py`:
  - `sample_price_df_with_nans_close` - AAPL with 3 NaN in close column
  - `sample_price_df_with_nans_ohlc` - MSFT with NaN in open, high, low columns
- Create test files with P0/unit markers:
  - `tests/stories/1.4/unit/test_1_4_unit_005.py` - Test validate_prices() with clean data reports no issues
  - `tests/stories/1.4/unit/test_1_4_unit_006.py` - Test _check_missing_values() detects NaN in close
  - `tests/stories/1.4/unit/test_1_4_unit_007.py` - Test _check_missing_values() detects NaN in OHLC
- Implement in `src/momo/data/validation.py`:
  - `_check_missing_values()` helper function to detect NaN/null in OHLC columns
    - Returns dict mapping ticker -> count of missing values
    - Checks open, high, low, close columns (critical columns)
  - Update `validate_prices()` to call `_check_missing_values()` and populate `missing_data_counts` in ValidationReport
  - Set `is_valid=False` if missing data detected, `is_valid=True` otherwise
  - Generate appropriate `summary_message`

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_00[5-7].py -v` (all pass)
- Run: `uv run mypy src/momo/data/validation.py` (passes)
- Verify clean data shows no issues
- Verify NaN detection works for individual and multiple columns

---

## Commit 4: feat(validation): implement date gap detection with market calendar awareness

**Tests:** 1.4-UNIT-008, 1.4-UNIT-009, 1.4-UNIT-010
**ACs:** 2
**Priority:** P1

**Setup:**
- Add fixtures to `tests/stories/1.4/conftest.py`:
  - `sample_price_df_with_10day_gap` - TSLA with 10-business-day gap (e.g., 2020-06-01 to 2020-06-15)
  - `sample_price_df_with_weekends_missing` - Typical weekday-only trading data
  - `sample_price_df_with_july4_missing` - Data missing 2020-07-03 (Independence Day observed)
- Create test files with P1/unit markers:
  - `tests/stories/1.4/unit/test_1_4_unit_008.py` - Test _check_date_gaps() detects 10-day gap
  - `tests/stories/1.4/unit/test_1_4_unit_009.py` - Test _check_date_gaps() ignores weekend gaps
  - `tests/stories/1.4/unit/test_1_4_unit_010.py` - Test _check_date_gaps() ignores market holidays
- Implement in `src/momo/data/validation.py`:
  - `_check_date_gaps()` helper function to detect suspicious gaps
    - Returns dict mapping ticker -> list of gap date ranges
    - Uses pandas business day logic to avoid weekend false positives
    - Documents limitation if NYSE holiday calendar not used
    - Threshold: gaps >= 10 business days flagged as suspicious
  - Update `validate_prices()` to call `_check_date_gaps()` and populate `date_gaps` field
  - Update `summary_message` to include gap information

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_00[8-10].py -v` (all pass)
- Run: `uv run mypy src/momo/data/validation.py` (passes)
- Verify suspicious gaps detected
- Verify weekends and common holidays don't trigger false positives

---

## Commit 5: feat(validation): implement adjustment consistency checks

**Tests:** 1.4-UNIT-011, 1.4-UNIT-012, 1.4-UNIT-013
**ACs:** 3
**Priority:** P0 (1.4-UNIT-011), P1 (others)

**Setup:**
- Add fixtures to `tests/stories/1.4/conftest.py`:
  - `sample_price_df_with_negative_price` - Ticker FAIL with negative close price
  - `sample_price_df_with_50pct_jump_no_div` - Ticker XYZ with 50% jump, dividend=0
  - `sample_price_df_with_aapl_split` - Realistic Apple 7:1 split data (June 2014)
- Create test files:
  - `tests/stories/1.4/unit/test_1_4_unit_011.py` - P0/unit - Test flags negative prices
  - `tests/stories/1.4/unit/test_1_4_unit_012.py` - P1/unit - Test flags 50% jump without dividend
  - `tests/stories/1.4/unit/test_1_4_unit_013.py` - P1/unit - Test allows legitimate AAPL split
- Implement in `src/momo/data/validation.py`:
  - `_check_adjustment_consistency()` helper function with heuristics:
    - Flag negative prices (always invalid)
    - Flag large price jumps (>40% threshold) without corresponding dividend/split info
    - Use day-over-day price change analysis
    - Returns list of tickers with suspected adjustment issues
  - Update `validate_prices()` to call `_check_adjustment_consistency()` and populate `adjustment_issues` field
  - Update `summary_message` and `is_valid` logic

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_01[1-3].py -v` (all pass)
- Run: `uv run mypy src/momo/data/validation.py` (passes)
- Verify negative prices detected
- Verify heuristic thresholds work for synthetic and real data

---

## Commit 6: feat(validation): implement index constituent retrieval via bridge

**Tests:** 1.4-UNIT-014, 1.4-UNIT-015, 1.4-UNIT-016, 1.4-INT-001
**ACs:** 4
**Priority:** P0 (unit tests and INT-001)

**Setup:**
- Add fixtures to `tests/stories/1.4/conftest.py`:
  - `mock_bridge_response_russell1000` - Mock list of ~1000 ticker symbols
- Create test files:
  - `tests/stories/1.4/unit/test_1_4_unit_014.py` - P0/unit - Test with mocked bridge
  - `tests/stories/1.4/unit/test_1_4_unit_015.py` - P0/unit - Test handles bridge timeout
  - `tests/stories/1.4/unit/test_1_4_unit_016.py` - P1/unit - Test raises on invalid index
  - `tests/stories/1.4/integration/test_1_4_int_001.py` - P0/integration - Real bridge call for Russell 1000
- Implement in `src/momo/data/validation.py`:
  - `get_index_constituents_at_date()` function:
    - Calls Norgate API via bridge.py (may need to add bridge helper function)
    - Uses `norgatedata.index_constituent_timeseries()` pattern
    - Returns list of ticker symbols for specified date
    - Handles bridge timeouts gracefully (raise BridgeError with context)
    - Validates index name (raise ValueError for invalid index)
    - Includes retry logic consistent with bridge pattern
    - Type hints: `-> list[str]`
- Add bridge helper to `src/momo/data/bridge.py` if needed for constituent retrieval
- Mark integration test with `@pytest.mark.integration` and skip if NDU unavailable

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_01[4-6].py -v` (all pass)
- Run: `uv run pytest tests/stories/1.4/integration/test_1_4_int_001.py -v` (passes if NDU available, skipped otherwise)
- Run: `uv run mypy src/momo/data/validation.py src/momo/data/bridge.py` (passes)
- Verify mocked tests pass without bridge
- Verify real bridge call returns ~1000 tickers in < 60s (if NDU available)

---

## Commit 7: feat(validation): implement delisting detection and report formatting

**Tests:** 1.4-UNIT-017, 1.4-UNIT-018, 1.4-UNIT-019, 1.4-UNIT-020, 1.4-UNIT-021
**ACs:** 5, 6, 8
**Priority:** P1 (1.4-UNIT-017, 018, 019, 020), P2 (1.4-UNIT-021)

**Setup:**
- Add fixtures to `tests/stories/1.4/conftest.py`:
  - `sample_price_df_with_enron_delisted` - Enron data ending 2001-12-02
  - `sample_price_df_with_recent_delisting` - Ticker ABC delisted 2019-06-15
  - `mock_validation_report` - Sample ValidationReport with various issues
- Create test files:
  - `tests/stories/1.4/unit/test_1_4_unit_017.py` - P1/unit - Test identifies Enron as delisted
  - `tests/stories/1.4/unit/test_1_4_unit_018.py` - P1/unit - Test returns last trading date
  - `tests/stories/1.4/unit/test_1_4_unit_019.py` - P1/unit - Test summary_message is concise
  - `tests/stories/1.4/unit/test_1_4_unit_020.py` - P1/unit - Test __str__ formats cleanly
  - `tests/stories/1.4/unit/test_1_4_unit_021.py` - P2/unit - Test module docstring has usage example
- Implement in `src/momo/data/validation.py`:
  - `check_delisting_status()` function:
    - Detects tickers with data ending > 30 days before query_end_date
    - Returns dict mapping ticker -> delisting date (last trading date)
    - Uses heuristic: if last date in time series is significantly before query end, likely delisted
  - Add `__str__()` method to ValidationReport dataclass:
    - Formatted output with section headers
    - Clear structure for readability
    - Summary appears prominently
  - Enhance module docstring with comprehensive usage example
  - Update `validate_prices()` to optionally call `check_delisting_status()` and populate `delisting_events`
  - Refine `summary_message` generation to be concise (< 200 chars) and human-readable

**Verification:**
- Run: `uv run pytest tests/stories/1.4/unit/test_1_4_unit_01[7-9].py tests/stories/1.4/unit/test_1_4_unit_020.py tests/stories/1.4/unit/test_1_4_unit_021.py -v` (all pass)
- Run: `uv run mypy src/momo/data/validation.py` (passes)
- Verify delisting detection works for historical cases
- Verify ValidationReport string formatting is readable
- Verify module docstring contains usage example

---

## Commit 8: test(validation): add integration tests for full pipeline and performance

**Tests:** 1.4-INT-002, 1.4-INT-003, 1.4-INT-004
**ACs:** 7, 8
**Priority:** P0 (INT-002), P1 (INT-003), P2 (INT-004)

**Setup:**
- Add fixtures to `tests/stories/1.4/conftest.py`:
  - `sample_price_df_100tickers` - Large dataset with 100 tickers, 252 trading days for performance testing
  - `cached_corrupt_test_data` - Pre-generated or fixture-generated DataFrame with multiple known issues:
    - AAPL: 5 NaN in close
    - MSFT: 10-day gap
    - TSLA: 50% jump without dividend
    - ENRN: Delisted (ends 2001-12-02)
- Create test files with integration markers:
  - `tests/stories/1.4/integration/test_1_4_int_002.py` - P0/integration - Full pipeline with corrupt data
  - `tests/stories/1.4/integration/test_1_4_int_003.py` - P1/integration - Performance test < 5s
  - `tests/stories/1.4/integration/test_1_4_int_004.py` - P2/integration - Manual report review
- Test comprehensive validation workflow:
  - INT-002: Load corrupt cached data, run validate_prices(), verify all 4 issue types detected
  - INT-003: Run validation on 100-ticker dataset, measure time < 5s
  - INT-004: Print ValidationReport, document readability findings in test output

**Verification:**
- Run: `uv run pytest tests/stories/1.4/integration/ -v` (all pass)
- Run: `uv run pytest tests/stories/1.4/ -v` (all 20 tests pass)
- Run: `uv run pytest tests/stories/1.4/ --cov=src/momo/data/validation --cov-report=term-missing` (coverage > 90%)
- Run: `uv run mypy tests/stories/1.4/` (passes)
- Verify full validation pipeline identifies all synthetic issues
- Verify performance meets < 5s requirement for 100 tickers
- Verify report output is human-readable

---

## Execution Order Summary

1. **Foundation & Exceptions** (Commit 1): ValidationError exception class
2. **Core Structure** (Commit 2): ValidationReport dataclass and validate_prices() skeleton
3. **Missing Data Detection** (Commit 3): NaN detection in OHLC columns
4. **Date Gap Detection** (Commit 4): Suspicious gap identification with market calendar awareness
5. **Adjustment Checks** (Commit 5): Negative price and jump detection heuristics
6. **Bridge Integration** (Commit 6): Index constituent retrieval via Norgate bridge
7. **Delisting & Formatting** (Commit 7): Delisting detection and report output formatting
8. **Integration & Performance** (Commit 8): Full pipeline validation and performance testing

## Implementation Workflow for Each Commit

Each commit is a **logical unit** containing both tests and implementation:

1. **Implement the logical unit**:
   - Create test files with test scenarios that define expected behavior
   - Implement the functionality (helper functions, dataclass methods, etc.) to satisfy tests
   - Add fixtures to conftest.py as needed
   - Ensure all type hints and docstrings are complete

2. **Verify**: Run the commit's tests plus mypy to confirm they pass:
   - `uv run pytest tests/stories/1.4/[unit|integration]/test_1_4_*.py -v`
   - `uv run mypy src/momo/data/validation.py`

3. **Commit**: Stage tests + implementation + fixtures together:
   - Example: `git add tests/stories/1.4/ src/momo/data/validation.py && git commit -m "..."`

**Key Principle:** One commit = one logical feature/component with its complete test coverage.

**Anti-pattern:** Don't create separate commits for "write tests" and "make tests pass" - this artificially splits logical units.

## Dependencies Between Commits

- **Commit 1** (ValidationError) must complete before Commit 2 (validation.py imports it)
- **Commit 2** (ValidationReport + skeleton) must complete before Commits 3-7 (validation logic depends on structure)
- **Commits 3-7** are independent of each other (can be developed in parallel if needed)
- **Commit 8** (integration tests) depends on Commits 2-7 (tests full pipeline)

**Recommended Linear Order:** 1 → 2 → 3 → 4 → 5 → 6 → 7 → 8

**Parallel Option:** After Commit 2, Commits 3-7 can be developed independently and merged in any order, followed by Commit 8.
