# Risk Profile: Story 1.3 - Implement Data Loading and Parquet Caching

**Date**: 2025-12-04
**Reviewer**: Quinn (Test Architect)
**Story**: 1.3 - Implement Data Loading and Parquet Caching

## Executive Summary

- **Total Risks Identified**: 10
- **Critical Risks**: 0
- **High Risks**: 2
- **Medium Risks**: 3
- **Low Risks**: 5
- **Risk Score**: 70/100 (Moderate - Acceptable for data infrastructure story)

**Overall Assessment**: Story 1.3 presents moderate risk typical of foundational data infrastructure. The two high-risk items (DATA-001 schema drift and TECH-002 partial failure handling) require careful attention during implementation and testing. No critical blockers identified. Recommended to proceed with enhanced test coverage for high-risk areas.

---

## Critical Risks Requiring Immediate Attention

**None identified** - No risks scored 9 (Critical).

---

## High Risks (Score 6)

### 1. DATA-001: Parquet Schema Drift

**Score: 6 (High)**
**Probability**: Medium (2) - Schema evolution during development is common, especially as data models are refined
**Impact**: High (3) - Could corrupt backtest results through silent calculation errors or cause runtime failures

**Description**: DataFrames cached with different schemas (missing columns, incorrect dtypes, reordered columns) could cause load failures or, worse, silent data corruption. Since the cache layer is foundational for all downstream calculations, schema inconsistencies would propagate through signal, portfolio, and backtest layers.

**Affected Components**:
- `cache.py::save_prices()`
- `cache.py::load_prices()`
- All consumers of cached data (future stories)

**Mitigation Strategy**: Preventive + Detective

**Actions**:
1. **Schema Validation on Save**: Implement schema validation in `save_prices()` to ensure DataFrame matches expected structure before caching
2. **Version Metadata**: Include schema version in Parquet metadata (e.g., `schema_version: 1.0`) to detect incompatible caches
3. **Dtype Enforcement**: Explicitly validate dtypes match expected schema from data-models.md
4. **MultiIndex Validation**: Assert MultiIndex structure `(date, symbol)` is present and correctly typed
5. **Cache Invalidation on Schema Change**: Implement `invalidate()` function to clear incompatible caches when schema evolves
6. **Type Hints**: Use strict type hints for DataFrame parameters with docstring schema documentation

**Testing Requirements**:
- **UNIT-005**: Test schema validation rejects DataFrames with missing columns
- **UNIT-006**: Test schema validation rejects DataFrames with incorrect dtypes
- **UNIT-007**: Test schema version mismatch detection (mock old version in metadata)
- **INT-004**: Integration test verifying schema consistency after round-trip save/load
- **INT-005**: Integration test with intentionally altered schema to verify rejection

**Residual Risk**: Low - Metadata versioning and validation should catch schema drift early

**Owner**: Dev
**Timeline**: Must be implemented before story completion

---

### 2. TECH-002: Bridge Integration Error Handling

**Score: 6 (High)**
**Probability**: High (3) - Norgate API failures for individual symbols are common (delisted stocks, data gaps, API timeouts)
**Impact**: Medium (2) - Partial failures could leave cache inconsistent or require full re-fetch

**Description**: During multi-symbol fetches, if some symbols fail (e.g., delisted tickers, API errors, data not available), the cache could be left in an inconsistent state with partial data. Without proper error handling, this could cause silent missing data in backtests or require expensive full re-fetches.

**Affected Components**:
- `loader.py::load_universe()`
- Error handling and retry logic
- Cache consistency mechanisms

**Mitigation Strategy**: Corrective + Detective

**Actions**:
1. **Graceful Degradation**: Continue fetching remaining symbols when individual symbols fail (already in story subtask)
2. **Error Aggregation**: Collect all errors and log summary with failed symbol list using structlog
3. **Partial Cache Storage**: Save successfully fetched symbols to cache even if some fail
4. **Failure Metadata**: Track failed symbols in cache metadata for retry identification
5. **Explicit Retry Mechanism**: Provide mechanism to retry only failed symbols (future enhancement)
6. **Clear Error Messages**: Raise informative exceptions indicating which symbols failed and why
7. **Test Symbol Validation**: Validate symbols exist in Norgate before attempting fetch (optional enhancement)

**Testing Requirements**:
- **UNIT-011**: Test partial failure handling with mocked bridge errors for some symbols
- **UNIT-012**: Test error aggregation and logging for multi-symbol failures
- **UNIT-013**: Test cache stores partial results when some symbols fail
- **INT-006**: Integration test with intentionally invalid symbols mixed with valid ones
- **INT-007**: Integration test verifying cache consistency after partial failures

**Residual Risk**: Medium - Some edge cases (e.g., API timeout mid-fetch) may still cause issues

**Owner**: Dev
**Timeline**: Must be implemented before story completion

---

## Medium Risks (Score 4)

### 3. TECH-001: Cache Path Collision

**Score: 4 (Medium)**
**Probability**: Medium (2) - Possible during parallel test execution or multi-user environments
**Impact**: Medium (2) - Could corrupt cache or cause race conditions

**Description**: Multiple processes or tests running concurrently could generate the same cache path and interfere with each other's cache files, leading to corrupted Parquet files or incorrect data being loaded.

**Mitigation**:
- Use atomic file operations for cache writes (write to temp file, then atomic rename)
- Include process ID or random component in temp file names
- Use file locking mechanisms if needed (advanced)
- Test suite uses `tmp_path` fixture to isolate test cache directories
- Document cache path generation algorithm clearly

**Testing Requirements**:
- **UNIT-008**: Test cache path generation produces consistent results for same inputs
- **UNIT-009**: Test concurrent save operations don't corrupt cache (if file locking implemented)

**Residual Risk**: Low with atomic operations and isolated test fixtures

---

### 4. DATA-003: Stale Cache Detection

**Score: 4 (Medium)**
**Probability**: Medium (2) - Inevitable as time passes and new trading days occur
**Impact**: Medium (2) - Backtests using stale data could produce incorrect results

**Description**: No mechanism to automatically detect when cached data is stale (e.g., new trading days have occurred, corporate actions updated). Users must manually invoke `force_refresh=True` or `invalidate()`.

**Mitigation**:
- Include `created_at` timestamp in cache metadata
- Document `force_refresh` parameter clearly in docstrings
- Provide `invalidate()` function for manual cache clearing
- Future enhancement: Add TTL (time-to-live) or smart staleness detection based on data age
- Log cache creation time when loading from cache for user awareness

**Testing Requirements**:
- **UNIT-010**: Test metadata includes creation timestamp
- **UNIT-014**: Test `force_refresh=True` bypasses existing cache
- **INT-008**: Integration test verifying `force_refresh` fetches fresh data

**Residual Risk**: Medium - Manual cache management required; acceptable for v1.0

---

### 5. DATA-004: Empty DataFrame Caching

**Score: 4 (Medium)**
**Probability**: Medium (2) - Could happen with invalid symbol lists, API outages, or edge cases
**Impact**: Medium (2) - Silent test failures or empty backtest results

**Description**: Caching empty DataFrames (when all symbols fail to fetch or invalid symbol list provided) would mask errors on subsequent cache loads, causing silent failures in tests or backtests.

**Mitigation**:
- Add validation in `save_prices()` to reject empty DataFrames
- Raise informative exception when attempting to cache empty data
- Log warnings when zero symbols successfully fetched
- Test for empty DataFrame rejection in unit tests

**Testing Requirements**:
- **UNIT-015**: Test `save_prices()` rejects empty DataFrame with clear error
- **UNIT-016**: Test `load_universe()` handles all-failed-symbols scenario gracefully

**Residual Risk**: Low with validation checks

---

## Low Risks (Score 2-3)

### 6. DATA-002: MultiIndex Preservation Failure

**Score: 3 (Low)**
**Probability**: Low (1) - Pandas/PyArrow handle MultiIndex well with default settings
**Impact**: High (3) - Would break downstream calculations

**Mitigation**: Explicitly test MultiIndex preservation in integration tests; use PyArrow engine as specified in story

**Testing**: **INT-004** verifies MultiIndex structure after round-trip

---

### 7. PERF-001: Sequential Symbol Fetching Performance

**Score: 3 (Low)**
**Probability**: High (3) - Design decision; inherent to current implementation
**Impact**: Low (1) - Mitigated by caching; only affects first fetch

**Mitigation**: Documented as deferred to future story; acceptable for v1.0 since cache eliminates repeated overhead

**Testing**: **INT-003** measures performance to establish baseline for future optimization

---

### 8. OPS-001: Missing Cache Directory Handling

**Score: 2 (Low)**
**Probability**: Low (1) - Rare; mostly in misconfigured environments
**Impact**: Medium (2) - Would prevent caching functionality

**Mitigation**: Story includes subtask for directory creation using `Path.mkdir(parents=True, exist_ok=True)`; error handling for disk space/permissions

**Testing**: **UNIT-002** verifies directory creation behavior

---

### 9. TECH-003: Type Annotation Drift

**Score: 2 (Low)**
**Probability**: Low (1) - Mypy strict mode catches most issues
**Impact**: Medium (2) - Runtime errors if None not handled

**Mitigation**: Strict mypy enforcement; explicit None handling in tests

**Testing**: Mypy type checking enforced in CI/CD

---

### 10. PERF-002: Parquet Compression Trade-offs

**Score: 3 (Low)**
**Probability**: High (3) - Inherent to compression choice
**Impact**: Low (1) - Disk space is cheap; speed prioritized

**Mitigation**: Snappy compression documented as acceptable trade-off; future stories can adjust if needed

---

## Risk Distribution

### By Category

- **Data Risks (DATA)**: 4 risks (1 high, 2 medium, 1 low) - **Primary Focus Area**
- **Technical Risks (TECH)**: 3 risks (1 high, 1 medium, 1 low)
- **Performance Risks (PERF)**: 2 risks (both low) - Acceptable
- **Operational Risks (OPS)**: 1 risk (low)
- **Security Risks (SEC)**: 0 risks - Not applicable for this story
- **Business Risks (BUS)**: 0 risks - Data infrastructure story

### By Component

- **cache.py**: 6 risks (1 high, 3 medium, 2 low)
- **loader.py**: 4 risks (1 high, 1 medium, 2 low)
- **Bridge integration**: 1 risk (high)
- **Infrastructure**: 1 risk (low)

### By Score

- **Score 6 (High)**: 2 risks - DATA-001, TECH-002
- **Score 4 (Medium)**: 3 risks - TECH-001, DATA-003, DATA-004
- **Score 3 (Low)**: 3 risks - DATA-002, PERF-001, PERF-002
- **Score 2 (Low)**: 2 risks - OPS-001, TECH-003

---

## Risk-Based Testing Strategy

### Priority 1: High Risk Tests (Must Have)

**Focus**: Schema validation and error handling

**Test Scenarios**:
1. **Schema Drift Detection** (DATA-001):
   - UNIT-005: Reject DataFrames missing required columns
   - UNIT-006: Reject DataFrames with incorrect dtypes
   - UNIT-007: Detect schema version mismatches
   - INT-004: Verify schema consistency after round-trip
   - INT-005: Test intentional schema alterations are rejected

2. **Partial Failure Handling** (TECH-002):
   - UNIT-011: Mock bridge errors for subset of symbols
   - UNIT-012: Verify error aggregation and logging
   - UNIT-013: Verify partial cache storage on failures
   - INT-006: Mix invalid and valid symbols in real fetch
   - INT-007: Verify cache consistency after partial failures

**Required Test Types**:
- Unit tests with mocking for isolated validation
- Integration tests with actual file I/O and edge cases
- Error injection tests to simulate API failures

**Test Data Requirements**:
- Sample DataFrames with various schema violations
- Mock bridge responses with partial failures
- Invalid symbol lists for error testing

### Priority 2: Medium Risk Tests (Should Have)

**Focus**: Cache path collisions, staleness, empty data

**Test Scenarios**:
1. **Cache Path Management** (TECH-001):
   - UNIT-008: Consistent path generation
   - UNIT-009: Concurrent operation safety (if applicable)

2. **Staleness Detection** (DATA-003):
   - UNIT-010: Metadata timestamp validation
   - UNIT-014: Force refresh bypasses cache
   - INT-008: Fresh data fetching

3. **Empty DataFrame Handling** (DATA-004):
   - UNIT-015: Reject empty DataFrames on save
   - UNIT-016: Handle all-failed-symbols scenario

**Required Test Types**:
- Unit tests for validation logic
- Integration tests for cache behavior

### Priority 3: Low Risk Tests (Standard Coverage)

**Focus**: Standard functional tests for documented behavior

**Test Scenarios**:
- MultiIndex preservation (INT-004)
- Performance baseline measurement (INT-003)
- Directory creation (UNIT-002)
- Type checking (Mypy enforcement)

**Test Types**:
- Standard unit and integration tests
- Performance benchmarking
- Static analysis (Mypy)

---

## Risk Acceptance Criteria

### Must Fix Before Merge

1. **DATA-001 (Schema Drift)**: Implement schema validation and version metadata
2. **TECH-002 (Partial Failures)**: Implement graceful degradation for multi-symbol errors
3. **DATA-004 (Empty DataFrames)**: Implement empty DataFrame rejection

### Can Merge with Mitigation

1. **TECH-001 (Path Collisions)**: Use `tmp_path` fixtures in tests; atomic operations for writes
2. **DATA-003 (Staleness)**: Document `force_refresh` usage; include timestamp metadata
3. **All Low Risks**: Acceptable as-is with documented mitigations

### Accepted Risks

1. **PERF-001 (Sequential Fetching)**: Explicitly deferred to future story; acceptable given caching benefit
2. **PERF-002 (Compression)**: Snappy chosen deliberately for speed over size
3. **DATA-002 (MultiIndex)**: Pandas/PyArrow handle well; covered by integration tests

---

## Monitoring Requirements

### Post-Merge Monitoring

Since this is a data infrastructure story without production deployment, monitoring focuses on development and test metrics:

1. **Test Execution Metrics**:
   - Cache hit/miss rates in test runs
   - Test execution time improvements from caching
   - Test failure patterns related to cache

2. **Development Metrics**:
   - Cache invalidation frequency during development
   - Schema evolution frequency requiring cache clears

3. **Future Production Monitoring** (for downstream stories):
   - Cache performance metrics (load time, size)
   - Bridge call frequency (should decrease with cache)
   - Error rates for symbol fetching

---

## Risk Review Triggers

Review and update this risk profile when:

1. **Schema Changes**: Any modifications to price data schema in data-models.md
2. **Bridge API Changes**: Updates to Norgate bridge interface or error handling
3. **Performance Issues**: Cache load times exceeding thresholds (>50ms)
4. **Batch Optimization**: When future story implements batch fetching (PERF-001 mitigation)
5. **Cache Strategy Changes**: TTL, staleness detection, or cache invalidation logic updates
6. **Test Failures**: Repeated test failures related to cache or data loading

---

## Risk Score Calculation

**Overall Story Risk Score**: 70/100

```
Base Score = 100

Deductions:
- High risks (6):  2 √ó 10 = 20 points
- Medium risks (4): 3 √ó 5 = 15 points
- Low risks (2-3): 5 √ó 2 = 10 points

Final Score = 100 - 20 - 15 + 5 = 70
```

**Interpretation**: Score of 70/100 indicates moderate risk, which is appropriate for foundational data infrastructure. The high-risk items are well-understood and have clear mitigation strategies. No critical blockers.

---

## Recommendations

### Testing Priority

1. **Run high-risk tests first**: Schema validation and partial failure handling
2. **Integration tests critical**: File I/O and round-trip operations must be tested with real filesystem
3. **Mock judiciously**: Unit tests should mock bridge calls, but integration tests need real Parquet I/O

### Development Focus

1. **Schema Validation**: Implement early in `cache.py` development
2. **Error Handling**: Build robust error aggregation in `loader.py` from start
3. **Metadata**: Include comprehensive metadata in cache files from first implementation
4. **Documentation**: Document cache path generation and schema expectations clearly

### Code Review Emphasis

1. Validate schema enforcement logic in `save_prices()`
2. Review error handling paths in `load_universe()` for partial failures
3. Verify atomic file operations for cache writes
4. Check MultiIndex preservation in Parquet save/load
5. Ensure comprehensive docstrings for DataFrame schemas

### Deployment Strategy

Not applicable - this is a data infrastructure story without production deployment. However:

1. **Merge Strategy**: Ensure all high-risk tests pass before merge
2. **Documentation**: Update architecture docs with cache implementation details
3. **Example Usage**: Provide example code for common cache operations

---

## Integration with Quality Gates

**Risk-Based Gate Recommendation**: **CONCERNS**

**Rationale**: Two high-risk items (score 6) require careful implementation and testing. While no critical blockers exist, the importance of data integrity in a backtesting framework warrants heightened scrutiny.

**Gate Criteria**:
- ‚úÖ **PASS if**: Both high-risk mitigations implemented and tested comprehensively
- ‚ö†Ô∏è **CONCERNS if**: High-risk tests incomplete or schema validation inadequate (current state)
- ‚ùå **FAIL if**: Schema validation missing or error handling fundamentally broken
- üîì **WAIVED if**: Team accepts data integrity risks (NOT RECOMMENDED)

**Specific Requirements for PASS**:
1. Schema validation implemented with tests UNIT-005, UNIT-006, UNIT-007
2. Partial failure handling tested via UNIT-011, UNIT-012, UNIT-013, INT-006, INT-007
3. All integration tests passing with actual file I/O
4. Empty DataFrame rejection implemented and tested

---

## Summary

Story 1.3 presents **moderate, manageable risk** for a foundational data infrastructure component. The primary concerns center on data integrity (schema drift) and robustness (partial failure handling), both of which have clear, actionable mitigation strategies.

**Key Strengths**:
- Clear scope with deferred optimizations
- Well-documented architecture and requirements
- Explicit test requirements in story

**Key Weaknesses**:
- Schema validation not explicitly called out in acceptance criteria
- Partial failure handling mentioned but needs detailed implementation spec
- Cache staleness detection is manual (acceptable for v1.0)

**Recommended Actions**:
1. Add explicit schema validation to acceptance criteria or implementation tasks
2. Enhance error handling subtasks with specific partial failure requirements
3. Proceed with implementation focusing on high-risk test coverage
4. Consider adding example code for common cache operations to documentation

**Gate Decision**: Recommend **CONCERNS** pending implementation of high-risk mitigations. Re-evaluate for **PASS** once schema validation and error handling tests demonstrate comprehensive coverage.
